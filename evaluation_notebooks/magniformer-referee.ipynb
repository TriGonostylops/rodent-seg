{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ================= CASCADED REFEREE CONFIGURATION =================\n",
    "STAGE1_PATH = \"/kaggle/input/datasets/gonoszgonosz/b2-1024-weights/final_rat_model_b3_1024\"\n",
    "\n",
    "STAGE2_BCE_PATH = \"/kaggle/working/final_rat_model_stage2_bce\"\n",
    "STAGE2_DICE_PATH = \"/kaggle/working/final_rat_model_stage2_dice\"\n",
    "\n",
    "INPUT_VIDEO = \"/kaggle/input/datasets/gonoszgonosz/rat-test-video/test.mp4\"\n",
    "OUTPUT_VIDEO = \"/kaggle/working/Cascaded_Referee_Grid.mp4\"\n",
    "\n",
    "CONFIDENCE = 0.5\n",
    "PADDING_RATIO = 0.25\n",
    "# ==================================================================\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def load_model_and_proc(path):\n",
    "    proc = SegformerImageProcessor.from_pretrained(path)\n",
    "    model = SegformerForSemanticSegmentation.from_pretrained(path).to(device)\n",
    "    model.eval()\n",
    "    return proc, model\n",
    "\n",
    "def get_prediction(model, processor, image_array):\n",
    "    h, w = image_array.shape[:2]\n",
    "    rgb_img = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)\n",
    "    inputs = processor(images=Image.fromarray(rgb_img), return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = torch.nn.functional.interpolate(\n",
    "            outputs.logits, size=(h, w), mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "        mask = (probs[0, 1, :, :] > CONFIDENCE).cpu().numpy().astype(np.uint8)\n",
    "    return mask\n",
    "\n",
    "def get_padded_bbox(mask, padding):\n",
    "    \"\"\"Calculates the 25% padded square bounding box from a mask.\"\"\"\n",
    "    coords = np.column_stack(np.where(mask > 0))\n",
    "    if coords.size == 0:\n",
    "        return None\n",
    "        \n",
    "    y_min, x_min = coords.min(axis=0)\n",
    "    y_max, x_max = coords.max(axis=0)\n",
    "    \n",
    "    bw, bh = x_max - x_min, y_max - y_min\n",
    "    pad_w, pad_h = int(bw * padding), int(bh * padding)\n",
    "    \n",
    "    x_min, y_min = max(0, x_min - pad_w), max(0, y_min - pad_h)\n",
    "    x_max, y_max = min(mask.shape[1], x_max + pad_w), min(mask.shape[0], y_max + pad_h)\n",
    "    \n",
    "    crop_w, crop_h = x_max - x_min, y_max - y_min\n",
    "    side = max(crop_w, crop_h)\n",
    "    cx, cy = (x_min + x_max) // 2, (y_min + y_max) // 2\n",
    "    \n",
    "    x_min, y_min = max(0, cx - side // 2), max(0, cy - side // 2)\n",
    "    x_max, y_max = min(mask.shape[1], x_min + side), min(mask.shape[0], y_min + side)\n",
    "    \n",
    "    return y_min, y_max, x_min, x_max\n",
    "\n",
    "def apply_overlay(image, mask, color, alpha=0.4):\n",
    "    \"\"\"Blends a solid color over the masked region.\"\"\"\n",
    "    overlay = np.full_like(image, color)\n",
    "    blended = cv2.addWeighted(image, 1 - alpha, overlay, alpha, 0)\n",
    "    res = image.copy()\n",
    "    res[mask == 1] = blended[mask == 1]\n",
    "    return res\n",
    "\n",
    "def main():\n",
    "    print(\"--- LOADING PIPELINE MODELS ---\")\n",
    "    proc1, model1 = load_model_and_proc(STAGE1_PATH)\n",
    "    proc2_bce, model2_bce = load_model_and_proc(STAGE2_BCE_PATH)\n",
    "    proc2_dice, model2_dice = load_model_and_proc(STAGE2_DICE_PATH)\n",
    "\n",
    "    cap = cv2.VideoCapture(INPUT_VIDEO)\n",
    "    w, h = int(cap.get(3)), int(cap.get(4))\n",
    "    fps = cap.get(5)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Grid output: 2W width, 2H height\n",
    "    out = cv2.VideoWriter(OUTPUT_VIDEO, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w * 2, h * 2))\n",
    "\n",
    "    print(\"--- STARTING 2x2 GRID INFERENCE ---\")\n",
    "    pbar = tqdm(total=total_frames)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        \n",
    "        # 1. STAGE 1: Global Search\n",
    "        stage1_mask = get_prediction(model1, proc1, frame)\n",
    "        bbox = get_padded_bbox(stage1_mask, PADDING_RATIO)\n",
    "        \n",
    "        # Initialize the 4 quadrants\n",
    "        res_full_bce = frame.copy()\n",
    "        res_full_dice = frame.copy()\n",
    "        res_mag_bce = np.zeros_like(frame)\n",
    "        res_mag_dice = np.zeros_like(frame)\n",
    "        \n",
    "        if bbox is not None:\n",
    "            y1, y2, x1, x2 = bbox\n",
    "            crop = frame[y1:y2, x1:x2]\n",
    "            \n",
    "            # Avoid crashing on zero-dimension crops at extreme edges\n",
    "            if crop.shape[0] > 0 and crop.shape[1] > 0:\n",
    "                # 2. STAGE 2: Magnified Expert Inference\n",
    "                crop_mask_bce = get_prediction(model2_bce, proc2_bce, crop)\n",
    "                crop_mask_dice = get_prediction(model2_dice, proc2_dice, crop)\n",
    "                \n",
    "                # 3. RECONSTRUCTION: Full Scale Top Half\n",
    "                full_mask_bce = np.zeros((h, w), dtype=np.uint8)\n",
    "                full_mask_dice = np.zeros((h, w), dtype=np.uint8)\n",
    "                full_mask_bce[y1:y2, x1:x2] = crop_mask_bce\n",
    "                full_mask_dice[y1:y2, x1:x2] = crop_mask_dice\n",
    "                \n",
    "                res_full_bce = apply_overlay(frame, full_mask_bce, (0, 0, 255)) # Red\n",
    "                res_full_dice = apply_overlay(frame, full_mask_dice, (0, 255, 0)) # Green\n",
    "                \n",
    "                # Draw Bounding Box to show Stage 1's contribution\n",
    "                cv2.rectangle(res_full_bce, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
    "                cv2.rectangle(res_full_dice, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
    "                \n",
    "                # 4. MAGNIFICATION: Bottom Half Visualization\n",
    "                crop_bce_colored = apply_overlay(crop, crop_mask_bce, (0, 0, 255))\n",
    "                crop_dice_colored = apply_overlay(crop, crop_mask_dice, (0, 255, 0))\n",
    "                \n",
    "                # Scale the crop up to WxH so it matches the grid quadrant size perfectly\n",
    "                res_mag_bce = cv2.resize(crop_bce_colored, (w, h), interpolation=cv2.INTER_LANCZOS4)\n",
    "                res_mag_dice = cv2.resize(crop_dice_colored, (w, h), interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "        # 5. LABELS\n",
    "        cv2.putText(res_full_bce, \"FULL: BCE WEIGHTED\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        cv2.putText(res_full_dice, \"FULL: DICE LOSS\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        cv2.putText(res_mag_bce, \"MAGNIFIED PERCEPTION: BCE\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        cv2.putText(res_mag_dice, \"MAGNIFIED PERCEPTION: DICE\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "        # 6. STITCH THE 2x2 GRID\n",
    "        top_row = np.hstack((res_full_bce, res_full_dice))\n",
    "        bottom_row = np.hstack((res_mag_bce, res_mag_dice))\n",
    "        grid_frame = np.vstack((top_row, bottom_row))\n",
    "\n",
    "        out.write(grid_frame)\n",
    "        pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    pbar.close()\n",
    "    print(f\"Cascaded 2x2 Referee Video Saved: {OUTPUT_VIDEO}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
