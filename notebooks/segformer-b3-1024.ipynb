{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 14727750,
     "sourceType": "datasetVersion",
     "datasetId": 9410959
    }
   ],
   "dockerImageVersionId": 31260,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "!pip install evaluate",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-04T08:15:03.189732Z",
     "iopub.execute_input": "2026-02-04T08:15:03.189967Z",
     "iopub.status.idle": "2026-02-04T08:15:09.040184Z",
     "shell.execute_reply.started": "2026-02-04T08:15:03.189936Z",
     "shell.execute_reply": "2026-02-04T08:15:09.039207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Collecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.4.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\nRequirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.5)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.18)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (26.0rc2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.3)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (22.0.0)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2026.1.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.12.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m84.1/84.1 kB\u001B[0m \u001B[31m3.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.6\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import Dataset, Image as DSImage\n",
    "from transformers import (\n",
    "    SegformerImageProcessor,\n",
    "    SegformerForSemanticSegmentation,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    logging\n",
    ")\n",
    "from torch import nn\n",
    "\n",
    "logging.set_verbosity_info()\n",
    "\n",
    "MODEL_NAME = \"nvidia/mit-b3\"\n",
    "OUTPUT_DIR = \"/kaggle/working/checkpoints_b3_1024\"\n",
    "FINAL_MODEL_DIR = \"/kaggle/working/final_rat_model_b3_1024\"\n",
    "\n",
    "IMAGE_DIR = \"/kaggle/input/rodent-data-2/processed/images\"\n",
    "MASK_DIR = \"/kaggle/input/rodent-data-2/processed/masks\"\n",
    "\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 6e-5\n",
    "BATCH_SIZE = 1              # Must be 1 for 1024px on T4\n",
    "GRAD_ACCUMULATION = 16      # Effective Batch Size = 16\n",
    "\n",
    "def monitor_gpu(interval=60):\n",
    "    while True:\n",
    "        try:\n",
    "            result = subprocess.check_output(\n",
    "                [\"nvidia-smi\", \"--query-gpu=utilization.gpu,memory.used,memory.total\", \"--format=csv,noheader,nounits\"]\n",
    "            ).decode().strip().split('\\n')\n",
    "            stats = [f\"GPU {i}: {line.split(',')[0]}% Util | {line.split(',')[1]}/{line.split(',')[2]} MB\" for i, line in enumerate(result)]\n",
    "            print(f\"\\n[GPU MONITOR] \" + \" | \".join(stats) + \"\\n\")\n",
    "        except Exception: pass\n",
    "        time.sleep(interval)\n",
    "\n",
    "def load_dataset():\n",
    "    print(f\"--- LOADING DATA FROM: {IMAGE_DIR} ---\")\n",
    "    if not os.path.exists(IMAGE_DIR):\n",
    "        raise FileNotFoundError(f\"CRITICAL: {IMAGE_DIR} does not exist.\")\n",
    "    if not os.path.exists(MASK_DIR):\n",
    "        raise FileNotFoundError(f\"CRITICAL: {MASK_DIR} does not exist.\")\n",
    "\n",
    "    all_images = [f for f in os.listdir(IMAGE_DIR) if f.endswith(('.jpg', '.png'))]\n",
    "    all_masks = [f for f in os.listdir(MASK_DIR) if f.endswith(('.jpg', '.png'))]\n",
    "    \n",
    "    img_map = {os.path.splitext(f)[0]: f for f in all_images}\n",
    "    mask_map = {os.path.splitext(f)[0]: f for f in all_masks}\n",
    "    \n",
    "    common_ids = sorted(list(set(img_map.keys()) & set(mask_map.keys())))\n",
    "    \n",
    "    print(f\"--- DIAGNOSTICS ---\")\n",
    "    print(f\"Valid Pairs:  {len(common_ids)}\")\n",
    "    \n",
    "    if len(common_ids) == 0:\n",
    "        raise ValueError(\"No matching image/mask pairs found!\")\n",
    "\n",
    "    final_image_paths = [os.path.join(IMAGE_DIR, img_map[i]) for i in common_ids]\n",
    "    final_mask_paths = [os.path.join(MASK_DIR, mask_map[i]) for i in common_ids]\n",
    "\n",
    "    ds = Dataset.from_dict({\"image\": final_image_paths, \"label\": final_mask_paths})\n",
    "    ds = ds.cast_column(\"image\", DSImage())\n",
    "    ds = ds.cast_column(\"label\", DSImage())\n",
    "    ds = ds.train_test_split(test_size=0.10, seed=42)\n",
    "    return ds\n",
    "\n",
    "processor = SegformerImageProcessor.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    reduce_labels=False,\n",
    "    do_resize=True,\n",
    "    size={\"height\": 1024, \"width\": 1024} \n",
    ")\n",
    "\n",
    "def train_transforms(example_batch):\n",
    "    images = [x.convert(\"RGB\") for x in example_batch[\"image\"]]\n",
    "    \n",
    "    labels = []\n",
    "    for x in example_batch[\"label\"]:\n",
    "        mask_np = np.array(x.convert(\"L\"))\n",
    "        mask_np = np.where(mask_np > 0, 1, 0).astype(np.uint8)\n",
    "        labels.append(mask_np)\n",
    "\n",
    "    return processor(images, labels, return_tensors=\"pt\")\n",
    "\n",
    "def sanity_check(ds):\n",
    "    print(\"--- RUNNING SANITY CHECK ---\")\n",
    "    sample = ds[\"train\"][0]\n",
    "    # Process one sample manually\n",
    "    output = train_transforms({\"image\": [sample[\"image\"]], \"label\": [sample[\"label\"]]})\n",
    "    unique_vals = torch.unique(output[\"labels\"]).tolist()\n",
    "    print(f\"Processed Mask Values: {unique_vals}\")\n",
    "    \n",
    "    if any(v > 1 for v in unique_vals):\n",
    "        raise ValueError(f\"❌ CRITICAL: Mask contains values {unique_vals}. Must be only [0, 1].\")\n",
    "    print(\"✅ DATA IS SAFE.\")\n",
    "\n",
    "metric = evaluate.load(\"mean_iou\")\n",
    "id2label = {0: \"background\", 1: \"rat\"}\n",
    "label2id = {\"background\": 0, \"rat\": 1}\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    with torch.no_grad():\n",
    "        logits, labels = eval_pred\n",
    "        logits = torch.from_numpy(logits)\n",
    "        logits = nn.functional.interpolate(\n",
    "            logits, size=labels.shape[-2:], mode=\"bilinear\", align_corners=False\n",
    "        ).argmax(dim=1)\n",
    "\n",
    "        metrics = metric.compute(\n",
    "            predictions=logits.numpy(),\n",
    "            references=labels.numpy(),\n",
    "            num_labels=2,\n",
    "            ignore_index=255,\n",
    "            reduce_labels=False,\n",
    "        )\n",
    "        return {k: v.tolist() if isinstance(v, np.ndarray) else v for k, v in metrics.items()}\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        \n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits, size=labels.shape[-2:], mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "        \n",
    "        weights = torch.tensor([1.0, 5.0]).to(logits.device)\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=weights)\n",
    "        \n",
    "        loss = loss_fct(upsampled_logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def main():\n",
    "    ds = load_dataset()\n",
    "    \n",
    "    sanity_check(ds)\n",
    "    \n",
    "    ds[\"train\"].set_transform(train_transforms)\n",
    "    ds[\"test\"].set_transform(train_transforms)\n",
    "\n",
    "    model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=2,\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        num_train_epochs=EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        gradient_accumulation_steps=GRAD_ACCUMULATION,\n",
    "        fp16=True,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=50,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=50,\n",
    "        save_total_limit=2,\n",
    "        logging_steps=10,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"mean_iou\",\n",
    "        report_to=\"none\",\n",
    "        remove_unused_columns=False\n",
    "    )\n",
    "\n",
    "    trainer = WeightedTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=ds[\"train\"],\n",
    "        eval_dataset=ds[\"test\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    last_checkpoint = None\n",
    "    if os.path.isdir(OUTPUT_DIR):\n",
    "        checkpoints = [d for d in os.listdir(OUTPUT_DIR) if d.startswith(\"checkpoint-\")]\n",
    "        if checkpoints:\n",
    "            checkpoints = sorted(checkpoints, key=lambda x: int(x.split(\"-\")[1]))\n",
    "            last_checkpoint = os.path.join(OUTPUT_DIR, checkpoints[-1])\n",
    "            print(f\"!!! RESUMING FROM: {last_checkpoint} !!!\")\n",
    "\n",
    "    print(f\"--- TRAINING START: MIT-B3 @ 1024x1024 ---\")\n",
    "    trainer.train(resume_from_checkpoint=last_checkpoint)\n",
    "\n",
    "    print(f\"--- SAVING TO {FINAL_MODEL_DIR} ---\")\n",
    "    trainer.save_model(FINAL_MODEL_DIR)\n",
    "    processor.save_pretrained(FINAL_MODEL_DIR)\n",
    "    print(\"DONE.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    p = multiprocessing.Process(target=monitor_gpu, daemon=True)\n",
    "    p.start()\n",
    "    main()"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-04T08:15:09.042742Z",
     "iopub.execute_input": "2026-02-04T08:15:09.043051Z",
     "iopub.status.idle": "2026-02-04T08:15:49.122684Z",
     "shell.execute_reply.started": "2026-02-04T08:15:09.043017Z",
     "shell.execute_reply": "2026-02-04T08:15:49.121009Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "2026-02-04 08:15:25.068165: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1770192925.287844      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1770192925.352048      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1770192925.873530      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770192925.873584      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770192925.873588      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770192925.873591      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "preprocessor_config.json:   0%|          | 0.00/272 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b84a731c7897451f93435cd737096172"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--nvidia--mit-b3/snapshots/0e0522cf0515903a0d35abc5adc9df78a25fde7c/preprocessor_config.json\n/usr/local/lib/python3.12/dist-packages/transformers/image_processing_base.py:417: UserWarning: The following named arguments are not valid for `SegformerImageProcessor.__init__` and were ignored: 'feature_extractor_type', 'reduce_labels'\n  image_processor = cls(**image_processor_dict)\nImage processor SegformerImageProcessor {\n  \"do_normalize\": true,\n  \"do_reduce_labels\": false,\n  \"do_rescale\": true,\n  \"do_resize\": true,\n  \"image_mean\": [\n    0.485,\n    0.456,\n    0.406\n  ],\n  \"image_processor_type\": \"SegformerImageProcessor\",\n  \"image_std\": [\n    0.229,\n    0.224,\n    0.225\n  ],\n  \"resample\": 2,\n  \"rescale_factor\": 0.00392156862745098,\n  \"size\": {\n    \"height\": 1024,\n    \"width\": 1024\n  }\n}\n\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading builder script: 0.00B [00:00, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff38679a6fbd4cbca8ed27560935b103"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "\nCRITICAL ERROR: Could not find 'images' and 'masks' folders.\nChecked: ['/kaggle/input/rodent-data-2/dataset/train/images', '/kaggle/input/rodent-data-2/dataset/processed/images', '/kaggle/input/rodent-data-2/images']\n",
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_55/2554957690.py\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m    217\u001B[0m     \u001B[0mp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmultiprocessing\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mProcess\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtarget\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmonitor_gpu\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdaemon\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    218\u001B[0m     \u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 219\u001B[0;31m     \u001B[0mmain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_55/2554957690.py\u001B[0m in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m    159\u001B[0m \u001B[0;31m# --- 6. MAIN ---\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mmain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 161\u001B[0;31m     \u001B[0mds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mload_dataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    162\u001B[0m     \u001B[0mds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"train\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_transform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_transforms\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    163\u001B[0m     \u001B[0mds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"test\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_transform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_transforms\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_55/2554957690.py\u001B[0m in \u001B[0;36mload_dataset\u001B[0;34m()\u001B[0m\n\u001B[1;32m     71\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"\\nCRITICAL ERROR: Could not find 'images' and 'masks' folders.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     72\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Checked: {POSSIBLE_IMG_PATHS}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 73\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mFileNotFoundError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Please check your dataset structure in /kaggle/input/rodent-data-2\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     74\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     75\u001B[0m     \u001B[0;31m# 2. Get all filenames\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: Please check your dataset structure in /kaggle/input/rodent-data-2"
     ],
     "ename": "FileNotFoundError",
     "evalue": "Please check your dataset structure in /kaggle/input/rodent-data-2",
     "output_type": "error"
    },
    {
     "name": "stdout",
     "text": "\n[GPU MONITOR] GPU 0: 0% Util |  3/ 15360 MB | GPU 1: 0% Util |  3/ 15360 MB\n\n\n[GPU MONITOR] GPU 0: 0% Util |  3/ 15360 MB | GPU 1: 0% Util |  3/ 15360 MB\n\n\n[GPU MONITOR] GPU 0: 0% Util |  3/ 15360 MB | GPU 1: 0% Util |  3/ 15360 MB\n\n\n[GPU MONITOR] GPU 0: 0% Util |  3/ 15360 MB | GPU 1: 0% Util |  3/ 15360 MB\n\n\n[GPU MONITOR] GPU 0: 0% Util |  3/ 15360 MB | GPU 1: 0% Util |  3/ 15360 MB\n\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 2
  }
 ]
}
