{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":14892684,"datasetId":9528810,"databundleVersionId":15756696}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport multiprocessing\nimport subprocess\nimport time\nimport numpy as np\nimport evaluate\nfrom datasets import Dataset, Image as DSImage\nfrom transformers import (\n    SegformerImageProcessor,\n    SegformerForSemanticSegmentation,\n    TrainingArguments,\n    Trainer,\n    logging\n)\nfrom torch import nn\n\nlogging.set_verbosity_info()\n\n# --- STAGE 2 CONFIGURATION ---\nMODEL_NAME = \"nvidia/mit-b3\" \nOUTPUT_DIR = \"/kaggle/working/checkpoints_stage2_expert\"\nFINAL_MODEL_DIR = \"/kaggle/working/final_rat_model_stage2_expert\"\n\nIMAGE_DIR = \"/kaggle/input/datasets/gonoszgonosz/magnified-rodents-1/stage2_dataset/images\"\nMASK_DIR = \"/kaggle/input/datasets/gonoszgonosz/magnified-rodents-1/stage2_dataset/masks\"\n\n# Training Hyperparameters for Fine-Tuning\nEPOCHS = 40                 # Slightly longer training for fine details\nLEARNING_RATE = 3e-5        # Lower learning rate for delicate boundary learning\nBATCH_SIZE = 4              # Can be higher than 1 because resolution is 512x512\nGRAD_ACCUMULATION = 4       # Effective batch size = 16\n\ndef monitor_gpu(interval=60):\n    while True:\n        try:\n            result = subprocess.check_output(\n                [\"nvidia-smi\", \"--query-gpu=utilization.gpu,memory.used,memory.total\", \"--format=csv,noheader,nounits\"]\n            ).decode().strip().split('\\n')\n            stats = [f\"GPU {i}: {line.split(',')[0]}% Util | {line.split(',')[1]}/{line.split(',')[2]} MB\" for i, line in enumerate(result)]\n            print(f\"\\n[GPU MONITOR] \" + \" | \".join(stats) + \"\\n\")\n        except Exception: pass\n        time.sleep(interval)\n\ndef load_dataset():\n    all_images = [f for f in os.listdir(IMAGE_DIR) if f.endswith(('.jpg', '.png'))]\n    all_masks = [f for f in os.listdir(MASK_DIR) if f.endswith(('.jpg', '.png'))]\n    img_map = {os.path.splitext(f)[0]: f for f in all_images}\n    mask_map = {os.path.splitext(f)[0]: f for f in all_masks}\n    common_ids = sorted(list(set(img_map.keys()) & set(mask_map.keys())))\n    \n    final_image_paths = [os.path.join(IMAGE_DIR, img_map[i]) for i in common_ids]\n    final_mask_paths = [os.path.join(MASK_DIR, mask_map[i]) for i in common_ids]\n\n    ds = Dataset.from_dict({\"image\": final_image_paths, \"label\": final_mask_paths})\n    ds = ds.cast_column(\"image\", DSImage())\n    ds = ds.cast_column(\"label\", DSImage())\n    ds = ds.train_test_split(test_size=0.10, seed=42)\n    return ds\n\n# --- PROCESSOR (Adjusted for 512x512 Stage 2 Crops) ---\nprocessor = SegformerImageProcessor.from_pretrained(\n    MODEL_NAME, do_resize=True, size={\"height\": 512, \"width\": 512} \n)\n\ndef train_transforms(example_batch):\n    images = [x.convert(\"RGB\") for x in example_batch[\"image\"]]\n    labels = []\n    for x in example_batch[\"label\"]:\n        mask_np = np.array(x.convert(\"L\"))\n        mask_np = np.where(mask_np > 0, 1, 0).astype(np.uint8)\n        labels.append(mask_np)\n    return processor(images, labels, return_tensors=\"pt\")\n\n# --- DICE LOSS IMPLEMENTATION ---\nclass DiceLoss(nn.Module):\n    def __init__(self, smooth=1e-6):\n        super(DiceLoss, self).__init__()\n        self.smooth = smooth\n\n    def forward(self, logits, targets):\n        probs = torch.softmax(logits, dim=1)\n        probs = probs[:, 1, :, :].contiguous().view(-1)\n        targets = targets.contiguous().view(-1).float()\n\n        intersection = (probs * targets).sum()\n        dice = (2. * intersection + self.smooth) / (probs.sum() + targets.sum() + self.smooth)\n        return 1 - dice\n\nclass ExpertTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n        labels = inputs.get(\"labels\")\n        outputs = model(**inputs)\n        logits = outputs.get(\"logits\")\n        \n        upsampled_logits = nn.functional.interpolate(\n            logits, size=labels.shape[-2:], mode=\"bilinear\", align_corners=False\n        )\n        \n        loss_fct = DiceLoss()\n        loss = loss_fct(upsampled_logits, labels)\n        return (loss, outputs) if return_outputs else loss\n\nmetric = evaluate.load(\"mean_iou\")\ndef compute_metrics(eval_pred):\n    with torch.no_grad():\n        logits, labels = eval_pred\n        logits_tensor = torch.from_numpy(logits)\n        logits_tensor = nn.functional.interpolate(\n            logits_tensor, size=labels.shape[-2:], mode=\"bilinear\", align_corners=False\n        ).argmax(dim=1)\n\n        metrics = metric.compute(\n            predictions=logits_tensor.numpy(),\n            references=labels,\n            num_labels=2,\n            ignore_index=255,\n            reduce_labels=False,\n        )\n        return {k: v.tolist() if isinstance(v, np.ndarray) else v for k, v in metrics.items()}\n\ndef main():\n    ds = load_dataset()\n    ds[\"train\"].set_transform(train_transforms)\n    ds[\"test\"].set_transform(train_transforms)\n\n    model = SegformerForSemanticSegmentation.from_pretrained(\n        MODEL_NAME, num_labels=2, id2label={0: \"background\", 1: \"rat\"}, label2id={\"background\": 0, \"rat\": 1}, ignore_mismatched_sizes=True\n    )\n\n    training_args = TrainingArguments(\n        output_dir=OUTPUT_DIR,\n        learning_rate=LEARNING_RATE,\n        num_train_epochs=EPOCHS,\n        per_device_train_batch_size=BATCH_SIZE,\n        per_device_eval_batch_size=BATCH_SIZE,\n        gradient_accumulation_steps=GRAD_ACCUMULATION,\n        fp16=True,\n        eval_strategy=\"steps\",\n        eval_steps=50,\n        save_strategy=\"steps\",\n        save_steps=50,\n        save_total_limit=2,\n        load_best_model_at_end=True,\n        metric_for_best_model=\"mean_iou\",\n        remove_unused_columns=False,\n        lr_scheduler_type=\"polynomial\", # Stabilizes fine boundary learning\n        warmup_steps=100\n    )\n\n    trainer = ExpertTrainer(\n        model=model,\n        args=training_args,\n        train_dataset=ds[\"train\"],\n        eval_dataset=ds[\"test\"],\n        compute_metrics=compute_metrics,\n    )\n\n    print(f\"--- TRAINING START: STAGE 2 EXPERT MODEL ---\")\n    trainer.train()\n\n    print(f\"--- SAVING TO {FINAL_MODEL_DIR} ---\")\n    trainer.save_model(FINAL_MODEL_DIR)\n    processor.save_pretrained(FINAL_MODEL_DIR)\n\nif __name__ == \"__main__\":\n    p = multiprocessing.Process(target=monitor_gpu, daemon=True)\n    p.start()\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}